{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow_datasets as tfds\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 19s 322us/step - loss: 0.2558 - accuracy: 0.9267\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 17s 286us/step - loss: 0.1019 - accuracy: 0.9696\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 17s 277us/step - loss: 0.0659 - accuracy: 0.9808\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.0470 - accuracy: 0.9857\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 19s 321us/step - loss: 0.0361 - accuracy: 0.9889\n",
      "10000/10000 [==============================] - 4s 377us/step\n",
      "test_acc:  0.9782000184059143\n"
     ]
    }
   ],
   "source": [
    "# keras mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test_acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "mnist_builder = tfds.builder(\"mnist\")\n",
    "\n",
    "mnist_builder.download_and_prepare()\n",
    "\n",
    "ds_train, ds_test = mnist_builder.as_dataset(split=[tfds.Split.TRAIN, tfds.Split.TEST])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ef7cf4435658>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mn_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mkeep_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "n_iterations = 1000\n",
    "batch_size = 128\n",
    "dropout = 0.5\n",
    "\n",
    "n_train = ds_train\n",
    "#n_validation = ds_validation\n",
    "n_test = ds_test\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_output])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "weights = {\n",
    "    \"w1\": tf.Variable(tf.truncated_normal([n_input, n_hidden1], stddev=0.1)),\n",
    "    \"w2\": tf.Variable(tf.truncated_normal([n_hidden1, n_hidden2], stddev=0.1)),\n",
    "    \"w3\": tf.Variable(tf.truncated_normal([n_hidden2, n_hidden3], stddev=0.1)),\n",
    "    \"out\": tf.Variable(tf.truncated_normal([n_hidden3, n_output], stddev=0.1)),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"b1\": tf.Variable(tf.constant(0.1, shape=[n_hidden1])),\n",
    "    \"b2\": tf.Variable(tf.constant(0.1, shape=[n_hidden2])),\n",
    "    \"b3\": tf.Variable(tf.constant(0.1, shape=[n_hidden3])),\n",
    "    \"out\": tf.Variable(tf.constant(0.1, shape=[n_output]))\n",
    "}\n",
    "\n",
    "layer_1 = tf.add(tf.matmul(X, weights[\"w1\"]), biases[\"b1\"])\n",
    "layer_2 = tf.add(tf.matmul(layer_1, weights[\"w2\"]), biases[\"b2\"])\n",
    "layer_3 = tf.add(tf.matmul(layer_2, weights[\"w3\"]), biases[\"b3\"])\n",
    "layer_drop = tf.nn.dropout(layer_3, keep_prob)\n",
    "output_layer = tf.matmul(layer_3, weights[\"out\"]) + biases[\"out\"]\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=Y, logits=output_layer\n",
    "    )\n",
    ")\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_pred = tf.equal(tf.argmax(output_layer, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    batch_x, batch_y = n_train.next_batch(batch_size)\n",
    "    sess.run(train_step, feed_dict={\n",
    "        X:batch_x, Y: batch_y, keep_prob: dropout\n",
    "    })\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        minibatch_loss, minibatch_accuracy = sess.run(\n",
    "            [cross_entropy, accuracy],\n",
    "            feed_dict={X: batch_x, Y: batch_y, keep_prob: 1.0}\n",
    "        )\n",
    "        print(\"Iteration\", str(i), \"\\t| loss =\", str(minibatch_loss), \"\\t| Accuracy =\", str(minibatch_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
